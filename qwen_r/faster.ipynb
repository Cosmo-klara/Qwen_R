{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb471b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,7\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from modelscope import snapshot_download\n",
    "from modelscope import Qwen2_5OmniForConditionalGeneration, Qwen2_5OmniProcessor, Qwen2_5OmniThinkerForConditionalGeneration\n",
    "import re\n",
    "from transformers.models.qwen2_vl.video_processing_qwen2_vl import Qwen2VLVideoProcessor\n",
    "from qwen_omni_utils import process_mm_info\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers.image_utils import SizeDict\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae29d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: ../../Qwen/cache/modelscope/Qwen/Qwen2.5-Omni-3B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 16:54:12,732 - modelscope - INFO - Target directory already exists, skipping creation.\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abafde0bbf544b60819a3e0576d6860a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 22,413,312 || all params: 4,734,622,720 || trainable%: 0.4734\n",
      "Model is in training mode: True\n"
     ]
    }
   ],
   "source": [
    "class OmniStepMemoryTracker:\n",
    "    def __init__(self, log_every=1):\n",
    "        self.step = 0\n",
    "        self.log_every = log_every\n",
    "\n",
    "    def log(self, batch):\n",
    "        if self.step % self.log_every != 0:\n",
    "            self.step += 1\n",
    "            return\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        alloc = torch.cuda.memory_allocated() / 1024**2\n",
    "        reserve = torch.cuda.memory_reserved() / 1024**2\n",
    "        peak = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "        # ---------- text ----------\n",
    "        seq_len = batch[\"input_ids\"].shape[1]\n",
    "        label_tokens = (batch[\"labels\"] != -100).sum().item()\n",
    "\n",
    "        # ---------- video ----------\n",
    "        if \"video_grid_thw\" in batch:\n",
    "            t, h, w = batch[\"video_grid_thw\"][0].tolist()\n",
    "            video_tokens = t * h * w\n",
    "        else:\n",
    "            t = h = w = video_tokens = 0\n",
    "\n",
    "        # ---------- audio ----------\n",
    "        if \"input_features\" in batch:\n",
    "            audio_tokens = batch[\"input_features\"].shape[-1]\n",
    "        else:\n",
    "            audio_tokens = 0\n",
    "\n",
    "        print(\n",
    "            f\"[Step {self.step:05d}] \"\n",
    "            f\"seq={seq_len}, label={label_tokens} | \"\n",
    "            f\"video={t}x{h}x{w}={video_tokens} | \"\n",
    "            f\"audio={audio_tokens} | \"\n",
    "            f\"CUDA alloc={alloc:.1f}MB peak={peak:.1f}MB reserve={reserve:.1f}MB\"\n",
    "        )\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "def replace_time_tokens_with_percentage(text, time_map, duration):\n",
    "\n",
    "    if not time_map or duration is None:\n",
    "        return text\n",
    "\n",
    "    def repl(match):\n",
    "        token = match.group(0)\n",
    "        if token not in time_map:\n",
    "            return token\n",
    "        t = time_map[token]\n",
    "        pct = t / duration * 100.0\n",
    "        return f\"{pct:.1f}%\"\n",
    "\n",
    "    return re.sub(r\"<s\\d+>|<e\\d+>\", repl, text)\n",
    "\n",
    "class OmniVideoConversationDataset(Dataset):\n",
    "    def __init__(self, json_path: str, video_root: str):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            self.raw_data = json.load(f)\n",
    "\n",
    "        self.video_root = video_root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.raw_data[idx]\n",
    "\n",
    "        video_id = item[\"id\"]\n",
    "        video_path = os.path.join(self.video_root, f\"{video_id}.mp4\")\n",
    "        audio_path = video_path.replace(\".mp4\", \".wav\")\n",
    "\n",
    "        duration = item.get(\"meta\", {}).get(\"duration\", None)\n",
    "        time_map = item.get(\"meta\", {}).get(\"token\", {})\n",
    "\n",
    "        return {\n",
    "            \"video_path\": video_path,\n",
    "            \"audio_path\": audio_path,\n",
    "            \"conversations\": copy.deepcopy(item[\"conversations\"]),\n",
    "            \"duration\": duration,\n",
    "            \"time_map\": time_map,\n",
    "        }\n",
    "\n",
    "class QwenOmniDataCollator:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "        self.tokenizer = processor.tokenizer\n",
    "\n",
    "    def _replace_time_tokens(self, conversations, time_map, duration):\n",
    "        if not time_map or duration is None:\n",
    "            return conversations\n",
    "\n",
    "        def repl(match):\n",
    "            token = match.group(0)\n",
    "            if token not in time_map:\n",
    "                return token\n",
    "            pct = time_map[token] / duration * 100\n",
    "            return f\"{pct:.1f}%\"\n",
    "\n",
    "        for turn in conversations:\n",
    "            turn[\"value\"] = re.sub(r\"<s\\d+>|<e\\d+>\", repl, turn[\"value\"])\n",
    "        return conversations\n",
    "    \n",
    "    def _split_rounds(self, conversations):\n",
    "        rounds = []\n",
    "        cur = []\n",
    "        for turn in conversations:\n",
    "            cur.append(turn)\n",
    "            if turn[\"from\"] == \"gpt\":\n",
    "                rounds.append(cur)\n",
    "                cur = []\n",
    "        return rounds\n",
    "\n",
    "    def _truncate_by_round_with_labels(\n",
    "        self,\n",
    "        base_chat,          # system + video/audio\n",
    "        rounds,             # [[h,g], [h,g], ...]\n",
    "        max_total_tokens    # input + label 最大 token 数\n",
    "    ):\n",
    "        rounds = copy.deepcopy(rounds)\n",
    "\n",
    "        while True:\n",
    "            chat = copy.deepcopy(base_chat)\n",
    "\n",
    "            # 统计 label token\n",
    "            total_tokens = 0\n",
    "            for r in rounds:\n",
    "                for t in r:\n",
    "                    role = \"user\" if t[\"from\"] == \"human\" else \"assistant\"\n",
    "                    chat.append({\n",
    "                        \"role\": role,\n",
    "                        \"content\": [{\"type\": \"text\", \"text\": t[\"value\"]}],\n",
    "                    })\n",
    "\n",
    "            # 用 tokenizer 计算 input token 长度\n",
    "            prompt = self.processor.apply_chat_template(\n",
    "                chat, tokenize=False, add_generation_prompt=False\n",
    "            )\n",
    "            input_tokens = len(self.tokenizer(prompt).input_ids)\n",
    "\n",
    "            # 统计 label token\n",
    "            label_tokens = 0\n",
    "            for r in rounds:\n",
    "                for t in r:\n",
    "                    if t[\"from\"] == \"gpt\":  # 只计算 assistant 输出\n",
    "                        label_tokens += len(self.tokenizer(t[\"value\"]).input_ids)\n",
    "\n",
    "            total_tokens = input_tokens + label_tokens\n",
    "            # print(input_tokens, label_tokens)\n",
    "\n",
    "            # 如果总长度符合限制，返回\n",
    "            if total_tokens <= max_total_tokens:\n",
    "                return chat\n",
    "\n",
    "            # ❗ 删除最早的一整轮\n",
    "            rounds = rounds[1:]\n",
    "\n",
    "\n",
    "    def _build_conversation(self, sample):\n",
    "        conversations = self._replace_time_tokens(\n",
    "            sample[\"conversations\"],\n",
    "            sample[\"time_map\"],\n",
    "            sample[\"duration\"],\n",
    "        )\n",
    "\n",
    "        base_chat = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\"}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"video\", \"video\": sample[\"video_path\"], \"fps\": 0.5, \"max_frames\": 50},\n",
    "                    {\"type\": \"audio\", \"audio\": sample[\"audio_path\"]},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        rounds = self._split_rounds(conversations)\n",
    "\n",
    "        chat = self._truncate_by_round_with_labels(\n",
    "            base_chat=base_chat,\n",
    "            rounds=rounds,\n",
    "            max_total_tokens=2560  # 或你显存可承受的最大 token 数\n",
    "        )\n",
    "\n",
    "        return chat\n",
    "\n",
    "    def _build_labels(self, input_ids):\n",
    "        labels = input_ids.clone()\n",
    "        labels[:] = -100\n",
    "\n",
    "        im_start = self.tokenizer.convert_tokens_to_ids(\"<|im_start|>\")\n",
    "        im_end = self.tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "        assistant = self.tokenizer.convert_tokens_to_ids(\"assistant\")\n",
    "\n",
    "        i = 0\n",
    "        while i < len(input_ids) - 1:\n",
    "            if input_ids[i] == im_start and input_ids[i + 1] == assistant:\n",
    "                j = i + 3  # skip <|im_start|> assistant \\n\n",
    "                while j < len(input_ids) and input_ids[j] != im_end:\n",
    "                    labels[j] = input_ids[j]\n",
    "                    j += 1\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "        return labels\n",
    "\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        texts, videos, audios = [], [], []\n",
    "\n",
    "        for sample in features:\n",
    "            conversation = self._build_conversation(sample)\n",
    "\n",
    "            prompt = self.processor.apply_chat_template(\n",
    "                conversation,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=False,\n",
    "            )\n",
    "            texts.append(prompt)\n",
    "\n",
    "            audios_, _, videos_ = process_mm_info(\n",
    "                    conversation, use_audio_in_video=False\n",
    "                )\n",
    "\n",
    "            videos.append(videos_[0] if videos_ else None)\n",
    "            audios.append(audios_[0] if audios_ else None)\n",
    "\n",
    "        batch = self.processor(\n",
    "            text=texts,\n",
    "            videos=videos,\n",
    "            audio=audios,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            use_audio_in_video=False,\n",
    "        )\n",
    "\n",
    "        labels = torch.stack([\n",
    "            self._build_labels(ids)\n",
    "            for ids in batch[\"input_ids\"]\n",
    "        ])\n",
    "\n",
    "        label_tokens = (labels != -100).sum().item()\n",
    "        # print(\"label tokens:\", label_tokens)\n",
    "\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        if not hasattr(self, \"_debug_printed\"):\n",
    "            self._debug_printed = True\n",
    "\n",
    "            print(\"\\n========== Omni Batch Debug ==========\")\n",
    "\n",
    "            # ---------- Text ----------\n",
    "            print(\"[Text]\")\n",
    "            print(\"input_ids:\", batch[\"input_ids\"].shape)\n",
    "            print(\"attention_mask:\", batch[\"attention_mask\"].shape)\n",
    "            print(\"labels:\", batch[\"labels\"].shape)\n",
    "            print(\n",
    "                \"label tokens:\",\n",
    "                (batch[\"labels\"] != -100).sum().item()\n",
    "            )\n",
    "\n",
    "            # ---------- Video ----------\n",
    "            if \"pixel_values_videos\" in batch:\n",
    "                pv = batch[\"pixel_values_videos\"]\n",
    "                print(\"\\n[Video]\")\n",
    "                print(\"pixel_values_videos:\", pv.shape)\n",
    "                print(\"dtype:\", pv.dtype)\n",
    "                print(\"video_grid_thw:\", batch.get(\"video_grid_thw\"))\n",
    "\n",
    "                video_mem = pv.numel() * pv.element_size() / 1024**2\n",
    "                print(f\"video tensor size: {video_mem:.2f} MB\")\n",
    "\n",
    "            # ---------- Audio ----------\n",
    "            for k in batch.keys():\n",
    "                if \"audio\" in k or \"input_features\" in k:\n",
    "                    v = batch[k]\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        mem = v.numel() * v.element_size() / 1024**2\n",
    "                        print(\"\\n[Audio]\")\n",
    "                        print(f\"{k}: {v.shape}, {mem:.2f} MB\")\n",
    "\n",
    "            print(\"=====================================\\n\")\n",
    "\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = OmniVideoConversationDataset(\n",
    "    json_path=\"../../LongVALE/data/longvale-sft-bp-7k.json\",\n",
    "    video_root=\"../../LongVALE/raw_videos_train/video_train_7240/\"\n",
    ")\n",
    "\n",
    "\n",
    "model_path = snapshot_download(\n",
    "    'Qwen/Qwen2.5-Omni-3B',\n",
    "    cache_dir=\"../../Qwen/cache/modelscope\"\n",
    ")\n",
    "\n",
    "model = Qwen2_5OmniThinkerForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "class FixedResQwen2VLVideoProcessor(Qwen2VLVideoProcessor):\n",
    "    def _preprocess(\n",
    "        self, videos, do_resize=True, size=None, interpolation=None, **kwargs\n",
    "    ):\n",
    "        # 固定分辨率\n",
    "        fixed_size = SizeDict(height=224, width=224)\n",
    "        for i, video in enumerate(videos):\n",
    "            videos[i] = self.resize(video, size=fixed_size, interpolation=interpolation)\n",
    "        return super()._preprocess(videos, do_resize=False, size=fixed_size, interpolation=interpolation, **kwargs)\n",
    "\n",
    "    # 保存 checkpoint 的时候需要\n",
    "    def to_dict(self):\n",
    "        # 返回可序列化的 dict，而不是整个对象\n",
    "        d = super().to_dict()\n",
    "        d.pop(\"some_non_serializable_attr\", None)\n",
    "        return d\n",
    "    \n",
    "video_processor = FixedResQwen2VLVideoProcessor.from_pretrained(model_path)\n",
    "\n",
    "processor = Qwen2_5OmniProcessor.from_pretrained(\n",
    "    model_path,\n",
    "    video_processor=video_processor,\n",
    ")\n",
    "\n",
    "\n",
    "# 配置LoRA\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"up_proj\", \"down_proj\"],\n",
    "    bias=\"none\",\n",
    "    # task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if (\n",
    "        \"audio_tower\" in name\n",
    "        or \"visual\" in name\n",
    "    ):\n",
    "        param.requires_grad = False\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "model.config.use_cache = False\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 检查模型是否在训练模式\n",
    "model.train()\n",
    "print(f\"Model is in training mode: {model.training}\")\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./r_models\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=1,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    fp16_full_eval=False,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=False,\n",
    "\n",
    "    torch_compile=True,\n",
    "    torch_compile_mode=\"default\",\n",
    "\n",
    "    # 似乎没有效果\n",
    "    use_liger_kernel=True,\n",
    "    liger_kernel_config={\n",
    "        \"cross_entropy\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "data_collator = QwenOmniDataCollator(processor)\n",
    "\n",
    "class DebugTrainer(Trainer):\n",
    "    def __init__(self, *args, memory_tracker=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.memory_tracker = memory_tracker\n",
    "\n",
    "    def training_step(self, model, inputs, *args, **kwargs):\n",
    "        if self.memory_tracker is not None:\n",
    "            self.memory_tracker.log(inputs)\n",
    "\n",
    "        return super().training_step(model, inputs, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "memory_tracker = OmniStepMemoryTracker(log_every=1)\n",
    "\n",
    "\n",
    "trainer = DebugTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    memory_tracker=memory_tracker,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ccbf3",
   "metadata": {},
   "source": [
    "todo:\n",
    "+ 拆成单轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aeb257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qwen-vl-utils using decord to read video.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Omni Batch Debug ==========\n",
      "[Text]\n",
      "input_ids: torch.Size([1, 10688])\n",
      "attention_mask: torch.Size([1, 10688])\n",
      "labels: torch.Size([1, 10688])\n",
      "label tokens: 547\n",
      "\n",
      "[Video]\n",
      "pixel_values_videos: torch.Size([6400, 1176])\n",
      "dtype: torch.float32\n",
      "video_grid_thw: tensor([[25, 16, 16]])\n",
      "video tensor size: 28.71 MB\n",
      "\n",
      "[Audio]\n",
      "input_features: torch.Size([1, 128, 30000]), 14.65 MB\n",
      "=====================================\n",
      "\n",
      "[Step 00000] seq=10688, label=547 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3319.0MB peak=3319.1MB reserve=3322.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1224 16:54:44.964000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [21/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1224 16:54:44.964000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [21/8]    function: '__call__' (/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/transformers/modeling_layers.py:60)\n",
      "W1224 16:54:44.964000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [21/8]    last reason: 21/0: ___check_obj_id(L['self']._modules['self_attn'].forward, 139998476696720)\n",
      "W1224 16:54:44.964000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [21/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1224 16:54:44.964000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [21/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "W1224 16:54:46.654000 80114 site-packages/torch/fx/experimental/symbolic_shapes.py:6307] [31/0] failed during evaluate_expr(Ne(u0, 7500), hint=None, size_oblivious=False, forcing_spec=False\n",
      "E1224 16:54:46.656000 80114 site-packages/torch/fx/experimental/recording.py:299] [31/0] failed while running evaluate_expr(*(Ne(u0, 7500), None), **{'fx_node': False})\n",
      "W1224 16:54:46.670000 80114 site-packages/torch/_dynamo/exc.py:304] [31/0] Backend compiler failed with a fake tensor exception at \n",
      "W1224 16:54:46.670000 80114 site-packages/torch/_dynamo/exc.py:304] [31/0]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py\", line 1754, in torch_dynamo_resume_in_get_audio_features_at_1747\n",
      "W1224 16:54:46.670000 80114 site-packages/torch/_dynamo/exc.py:304] [31/0]     if audio_features.shape[0] != sum(audio_output_lengths.tolist()):\n",
      "W1224 16:54:46.670000 80114 site-packages/torch/_dynamo/exc.py:304] [31/0] Adding a graph break.\n",
      "W1224 16:55:02.598000 80114 site-packages/torch/fx/experimental/symbolic_shapes.py:6307] [42/0] failed during evaluate_expr(Eq(u0, 0), hint=None, size_oblivious=False, forcing_spec=False\n",
      "E1224 16:55:02.599000 80114 site-packages/torch/fx/experimental/recording.py:299] [42/0] failed while running evaluate_expr(*(Eq(u0, 0), None), **{'fx_node': False})\n",
      "/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "W1224 16:55:03.030000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [9/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1224 16:55:03.030000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [9/8]    function: 'new_forward' (/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/accelerate/hooks.py:169)\n",
      "W1224 16:55:03.030000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [9/8]    last reason: 9/0: not L['args']                                               \n",
      "W1224 16:55:03.030000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [9/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1224 16:55:03.030000 80114 site-packages/torch/_dynamo/convert_frame.py:906] [9/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] WON'T CONVERT torch_dynamo_resume_in_forward_at_1553 /home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py line 1553 \n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 675, in _compile_fx_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 908, in codegen_and_compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     _recursive_post_grad_passes(gm, is_inference=is_inference)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 334, in _recursive_post_grad_passes\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     post_grad_passes(gm, is_inference)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 107, in post_grad_passes\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     GraphTransformObserver(gm, f\"pass_pattern_{i}\").apply_graph_pass(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/fx/passes/graph_transform_observer.py\", line 70, in apply_graph_pass\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return pass_fn(self.gm.graph)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/pattern_matcher.py\", line 1773, in apply\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     if is_match(m) and entry.extra_check(m):\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/fx_passes/quantization.py\", line 1477, in fn\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     scales = match.kwargs[\"scales\"].meta[\"val\"]\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] AttributeError: 'float' object has no attribute 'meta'\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 675, in _compile_fx_inner\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 908, in codegen_and_compile\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     _recursive_post_grad_passes(gm, is_inference=is_inference)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/compile_fx.py\", line 334, in _recursive_post_grad_passes\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     post_grad_passes(gm, is_inference)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 107, in post_grad_passes\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     GraphTransformObserver(gm, f\"pass_pattern_{i}\").apply_graph_pass(\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/fx/passes/graph_transform_observer.py\", line 70, in apply_graph_pass\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     return pass_fn(self.gm.graph)\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/pattern_matcher.py\", line 1773, in apply\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     if is_match(m) and entry.extra_check(m):\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/_inductor/fx_passes/quantization.py\", line 1477, in fn\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233]     scales = match.kwargs[\"scales\"].meta[\"val\"]\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] AttributeError: 'float' object has no attribute 'meta'\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1224 16:56:10.324000 80114 site-packages/torch/_dynamo/convert_frame.py:1233] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='7240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/7240 3:18:35 < 11:28:10, 0.14 it/s, Epoch 0.22/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.352200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.551900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.620200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.634300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.604800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.331400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.484100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.259700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.577100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.567900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.527900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.377800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.359500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.202900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>1.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.335600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.464400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>1.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>1.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>1.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>1.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>1.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>1.257300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>1.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>1.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>1.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>1.213300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.963500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>1.612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.587700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.213200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>1.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>1.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>1.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>1.636100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.448600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>1.603700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>1.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>1.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>1.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>1.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>1.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.896700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>1.587600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>1.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>1.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>1.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>1.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>1.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.443200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>1.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645</td>\n",
       "      <td>1.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.571800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655</td>\n",
       "      <td>1.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>1.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>1.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.344900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>1.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>1.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.471600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>1.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>1.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.307700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>1.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>1.565300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>1.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>1.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>1.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785</td>\n",
       "      <td>1.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.559200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>1.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>1.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>1.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.635900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>1.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>1.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>1.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855</td>\n",
       "      <td>1.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.609600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865</td>\n",
       "      <td>1.624400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>1.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.505500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>1.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>1.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.381600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905</td>\n",
       "      <td>1.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915</td>\n",
       "      <td>1.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>1.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>1.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.354300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>1.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>1.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>0.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.381300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>1.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985</td>\n",
       "      <td>1.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.686400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>1.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.758200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1005</td>\n",
       "      <td>1.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015</td>\n",
       "      <td>1.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.338200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>1.303900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035</td>\n",
       "      <td>1.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.459500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1045</td>\n",
       "      <td>1.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>1.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.679800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065</td>\n",
       "      <td>1.421800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>1.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.501900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>1.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095</td>\n",
       "      <td>0.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1105</td>\n",
       "      <td>1.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1115</td>\n",
       "      <td>1.223700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.527000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>1.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1135</td>\n",
       "      <td>1.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1145</td>\n",
       "      <td>1.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>1.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1165</td>\n",
       "      <td>1.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>1.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1185</td>\n",
       "      <td>1.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195</td>\n",
       "      <td>1.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1205</td>\n",
       "      <td>1.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>1.550700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.298500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>1.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1235</td>\n",
       "      <td>1.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245</td>\n",
       "      <td>1.509800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255</td>\n",
       "      <td>1.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>1.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1285</td>\n",
       "      <td>1.327600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>1.559500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>1.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1315</td>\n",
       "      <td>1.256600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>1.438400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>1.358600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>1.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>1.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1345</td>\n",
       "      <td>1.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.570700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1355</td>\n",
       "      <td>1.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>1.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>1.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>1.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>1.615800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1385</td>\n",
       "      <td>1.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>1.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1395</td>\n",
       "      <td>1.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1405</td>\n",
       "      <td>1.242100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>1.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1415</td>\n",
       "      <td>1.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>1.483100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>1.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1435</td>\n",
       "      <td>1.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1445</td>\n",
       "      <td>1.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>1.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>1.423500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1465</td>\n",
       "      <td>1.348700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>1.548500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>1.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>1.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485</td>\n",
       "      <td>1.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>1.361100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1495</td>\n",
       "      <td>1.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505</td>\n",
       "      <td>1.511700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>1.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1515</td>\n",
       "      <td>1.502400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>1.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>1.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>1.273900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1535</td>\n",
       "      <td>1.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>1.285700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1545</td>\n",
       "      <td>1.532400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1555</td>\n",
       "      <td>1.241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>1.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>1.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>1.316300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>1.487200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1585</td>\n",
       "      <td>1.060900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>1.386500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>1.546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605</td>\n",
       "      <td>1.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>1.276300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1615</td>\n",
       "      <td>1.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>1.412200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00001] seq=2188, label=210 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=12853.4MB reserve=13480.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00002] seq=5595, label=993 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13480.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuchi/anaconda3/envs/qwen_lora/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00003] seq=7021, label=314 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00004] seq=6892, label=136 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x47ecef00] mmco: unref short failure\n",
      "[h264 @ 0x47ecef00] mmco: unref short failure\n",
      "[h264 @ 0x47ecef00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00005] seq=7297, label=82 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00006] seq=5058, label=146 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00007] seq=7377, label=726 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00008] seq=5146, label=182 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n",
      "[h264 @ 0x489c60c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00009] seq=10415, label=1237 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00010] seq=6295, label=250 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00011] seq=2054, label=111 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00012] seq=10288, label=461 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00013] seq=2681, label=58 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.3MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00014] seq=3984, label=148 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=12853.4MB reserve=13486.0MB\n",
      "[Step 00015] seq=10908, label=708 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12853.4MB reserve=13486.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x47fde280] mmco: unref short failure\n",
      "[h264 @ 0x47fde280] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00016] seq=7949, label=121 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00017] seq=4532, label=146 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00018] seq=7116, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00019] seq=8731, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00020] seq=9467, label=57 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00021] seq=2390, label=92 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00022] seq=10909, label=660 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12951.2MB reserve=13666.0MB\n",
      "[Step 00023] seq=9485, label=308 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00024] seq=5606, label=431 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00025] seq=9024, label=608 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00026] seq=10030, label=853 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00027] seq=7238, label=49 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00028] seq=9622, label=438 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00029] seq=9412, label=42 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00030] seq=10419, label=508 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00031] seq=5915, label=174 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00032] seq=10717, label=736 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00033] seq=6466, label=345 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00034] seq=2695, label=398 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00035] seq=5003, label=337 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00036] seq=8704, label=446 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00037] seq=3129, label=121 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00038] seq=8945, label=295 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00039] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00040] seq=4951, label=73 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00041] seq=10918, label=624 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12952.1MB reserve=13666.0MB\n",
      "[Step 00042] seq=3329, label=29 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00043] seq=5683, label=239 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x489dba00] mmco: unref short failure\n",
      "[h264 @ 0x489dba00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00044] seq=2116, label=46 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00045] seq=4132, label=720 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00046] seq=10701, label=592 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x47cc2780] mmco: unref short failure\n",
      "[h264 @ 0x47cc2780] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00047] seq=9436, label=71 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00048] seq=10164, label=436 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00049] seq=10880, label=761 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00050] seq=3077, label=177 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00051] seq=9915, label=285 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00052] seq=7306, label=69 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00053] seq=10811, label=713 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00054] seq=9419, label=119 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00055] seq=10198, label=1020 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00056] seq=1468, label=188 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00057] seq=4184, label=114 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00058] seq=10347, label=372 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00059] seq=6394, label=774 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00060] seq=5573, label=112 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00061] seq=5149, label=87 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00062] seq=4997, label=419 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00063] seq=10791, label=863 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00064] seq=9546, label=163 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00065] seq=7267, label=277 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00066] seq=10385, label=729 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00067] seq=7604, label=240 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00068] seq=10782, label=534 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00069] seq=7154, label=88 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00070] seq=5674, label=304 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00071] seq=2826, label=136 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00072] seq=9569, label=386 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00073] seq=10841, label=762 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00074] seq=10264, label=1085 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00075] seq=2615, label=107 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00076] seq=11085, label=543 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=12960.0MB reserve=13686.0MB\n",
      "[Step 00077] seq=7388, label=335 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00078] seq=8409, label=200 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00079] seq=10174, label=331 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00080] seq=10544, label=451 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00081] seq=1640, label=41 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00082] seq=10753, label=417 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00083] seq=4558, label=489 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00084] seq=5988, label=479 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00085] seq=8184, label=488 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00086] seq=9488, label=37 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00087] seq=7488, label=303 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00088] seq=7950, label=653 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00089] seq=11048, label=610 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00090] seq=9325, label=47 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00091] seq=11048, label=574 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00092] seq=10355, label=1177 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x496f2cc0] mmco: unref short failure\n",
      "[h264 @ 0x496f2cc0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00093] seq=3204, label=90 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00094] seq=6792, label=185 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00095] seq=5957, label=99 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00096] seq=10973, label=629 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00097] seq=5981, label=229 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00098] seq=6148, label=236 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00099] seq=9575, label=91 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00100] seq=6604, label=148 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00101] seq=8853, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00102] seq=3293, label=163 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00103] seq=5369, label=258 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00104] seq=4608, label=134 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00105] seq=6675, label=557 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00106] seq=6158, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00107] seq=9940, label=236 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00108] seq=8436, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00109] seq=10683, label=940 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00110] seq=3016, label=47 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00111] seq=6032, label=303 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00112] seq=5921, label=318 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00113] seq=7854, label=269 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x52e3ed40] mmco: unref short failure\n",
      "[h264 @ 0x52e3ed40] mmco: unref short failure\n",
      "[h264 @ 0x52e3ed40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00114] seq=3995, label=222 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00115] seq=8381, label=392 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00116] seq=1656, label=14 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00117] seq=10858, label=724 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00118] seq=10917, label=685 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00119] seq=4453, label=54 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00120] seq=4676, label=287 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00121] seq=4787, label=402 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00122] seq=8116, label=178 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00123] seq=6785, label=385 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00124] seq=8505, label=1030 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00125] seq=9008, label=218 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00126] seq=10973, label=672 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00127] seq=10723, label=685 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00128] seq=9405, label=351 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00129] seq=7454, label=729 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00130] seq=9175, label=385 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00131] seq=10907, label=710 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00132] seq=4246, label=175 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00133] seq=10375, label=1192 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00134] seq=3121, label=134 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00135] seq=3717, label=84 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00136] seq=8154, label=227 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00137] seq=10209, label=488 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00138] seq=6306, label=313 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00139] seq=7049, label=476 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00140] seq=8061, label=334 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00141] seq=8391, label=74 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00142] seq=5568, label=357 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00143] seq=1768, label=196 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00144] seq=9931, label=601 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00145] seq=5470, label=50 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00146] seq=11007, label=629 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00147] seq=10979, label=613 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00148] seq=10404, label=358 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00149] seq=6619, label=432 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00150] seq=4599, label=121 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00151] seq=10570, label=599 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00152] seq=6095, label=374 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00153] seq=5652, label=253 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00154] seq=5638, label=101 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00155] seq=10166, label=426 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00156] seq=2729, label=95 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00157] seq=3718, label=87 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00158] seq=6618, label=322 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00159] seq=2090, label=364 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00160] seq=5355, label=304 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00161] seq=5702, label=329 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00162] seq=9285, label=102 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00163] seq=5263, label=259 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00164] seq=10579, label=539 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00165] seq=6111, label=74 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00166] seq=6003, label=218 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00167] seq=6184, label=73 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00168] seq=6251, label=256 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00169] seq=6752, label=455 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00170] seq=10008, label=337 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00171] seq=11064, label=532 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00172] seq=7545, label=152 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00173] seq=10705, label=589 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00174] seq=8652, label=441 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00175] seq=5667, label=305 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00176] seq=3697, label=49 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00177] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00178] seq=1314, label=14 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00179] seq=10942, label=644 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49690440] mmco: unref short failure\n",
      "[h264 @ 0x49690440] mmco: unref short failure\n",
      "[h264 @ 0x49690440] mmco: unref short failure\n",
      "[h264 @ 0x49690440] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00180] seq=4117, label=404 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00181] seq=9101, label=1021 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00182] seq=9281, label=46 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00183] seq=3683, label=249 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00184] seq=5983, label=590 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00185] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00186] seq=2510, label=58 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00187] seq=3981, label=83 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00188] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00189] seq=5252, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00190] seq=9577, label=398 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00191] seq=5863, label=603 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00192] seq=10098, label=354 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00193] seq=5398, label=229 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00194] seq=9688, label=197 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00195] seq=9948, label=771 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00196] seq=1319, label=37 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00197] seq=1457, label=13 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00198] seq=3366, label=325 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00199] seq=1958, label=157 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00200] seq=4115, label=42 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00201] seq=10188, label=404 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00202] seq=5277, label=87 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00203] seq=10884, label=572 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00204] seq=10892, label=618 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9a5c8c40] mmco: unref short failure\n",
      "[h264 @ 0x9a5c8c40] mmco: unref short failure\n",
      "[h264 @ 0x9a5c8c40] mmco: unref short failure\n",
      "[h264 @ 0x9a5c8c40] mmco: unref short failure\n",
      "[h264 @ 0x9a5c8c40] mmco: unref short failure\n",
      "[h264 @ 0x9a5c8c40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00205] seq=7730, label=118 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00206] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00207] seq=10710, label=526 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00208] seq=3438, label=149 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00209] seq=11004, label=649 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00210] seq=9761, label=206 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00211] seq=10017, label=336 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00212] seq=11018, label=623 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00213] seq=11001, label=617 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00214] seq=8908, label=59 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00215] seq=4906, label=58 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00216] seq=10096, label=1190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00217] seq=9785, label=606 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00218] seq=9672, label=494 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00219] seq=6144, label=654 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00220] seq=8340, label=870 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00221] seq=11034, label=582 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00222] seq=3364, label=39 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00223] seq=5725, label=433 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00224] seq=6522, label=531 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00225] seq=9636, label=451 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00226] seq=1666, label=40 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00227] seq=10252, label=468 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00228] seq=9820, label=194 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00229] seq=9361, label=440 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00230] seq=2468, label=526 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00231] seq=2595, label=70 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00232] seq=5572, label=227 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00233] seq=8888, label=666 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00234] seq=6209, label=101 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00235] seq=9418, label=314 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00236] seq=5556, label=293 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49531c00] mmco: unref short failure\n",
      "[h264 @ 0x49531c00] mmco: unref short failure\n",
      "[h264 @ 0x49531c00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00237] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00238] seq=10988, label=622 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49531c00] mmco: unref short failure\n",
      "[h264 @ 0x49531c00] mmco: unref short failure\n",
      "[h264 @ 0x49531c00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00239] seq=4673, label=105 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00240] seq=10538, label=646 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00241] seq=6671, label=65 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00242] seq=6494, label=405 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00243] seq=2313, label=85 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00244] seq=3101, label=90 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00245] seq=7792, label=703 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00246] seq=4931, label=103 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00247] seq=1506, label=69 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00248] seq=4902, label=118 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00249] seq=4617, label=12 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00250] seq=8945, label=1029 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00251] seq=9025, label=112 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00252] seq=3056, label=354 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00253] seq=4573, label=77 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00254] seq=10852, label=705 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00255] seq=10922, label=642 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00256] seq=1339, label=57 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00257] seq=5632, label=143 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00258] seq=4063, label=321 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00259] seq=10254, label=457 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00260] seq=5101, label=493 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00261] seq=7862, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00262] seq=5093, label=47 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00263] seq=6143, label=82 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00264] seq=8306, label=303 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00265] seq=2899, label=284 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00266] seq=2471, label=14 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00267] seq=11026, label=595 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00268] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00269] seq=10521, label=501 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00270] seq=7692, label=380 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00271] seq=5096, label=105 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00272] seq=7347, label=27 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00273] seq=2918, label=110 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9f00e640] mmco: unref short failure\n",
      "[h264 @ 0x9f00e640] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00274] seq=2358, label=282 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00275] seq=10885, label=670 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00276] seq=9572, label=134 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00277] seq=9254, label=348 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00278] seq=9819, label=615 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00279] seq=7899, label=354 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9c84b000] mmco: unref short failure\n",
      "[h264 @ 0x9c84b000] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00280] seq=6322, label=155 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00281] seq=2925, label=136 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00282] seq=2635, label=179 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00283] seq=9404, label=226 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00284] seq=7543, label=369 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00285] seq=9381, label=165 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00286] seq=7178, label=102 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00287] seq=9966, label=557 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00288] seq=5421, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00289] seq=4510, label=40 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00290] seq=3293, label=244 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00291] seq=6098, label=480 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00292] seq=1604, label=79 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00293] seq=9791, label=215 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00294] seq=5045, label=57 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00295] seq=10313, label=300 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00296] seq=5174, label=363 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00297] seq=9613, label=312 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00298] seq=8612, label=28 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00299] seq=10349, label=533 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00300] seq=10996, label=612 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9b324d40] mmco: unref short failure\n",
      "[h264 @ 0x9b324d40] mmco: unref short failure\n",
      "[h264 @ 0x9b324d40] mmco: unref short failure\n",
      "[h264 @ 0x9b324d40] mmco: unref short failure\n",
      "[h264 @ 0x9b324d40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00301] seq=8758, label=243 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00302] seq=5717, label=409 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00303] seq=7658, label=165 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00304] seq=6553, label=664 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00305] seq=4896, label=324 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00306] seq=7292, label=727 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00307] seq=6951, label=902 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00308] seq=7340, label=544 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00309] seq=1532, label=82 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00310] seq=5971, label=535 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00311] seq=4305, label=91 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00312] seq=3123, label=61 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00313] seq=11019, label=633 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00314] seq=8092, label=134 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00315] seq=6833, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00316] seq=5438, label=239 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00317] seq=9520, label=425 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00318] seq=9963, label=351 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00319] seq=4235, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00320] seq=4689, label=193 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00321] seq=7389, label=325 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00322] seq=10021, label=839 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00323] seq=4549, label=225 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00324] seq=10216, label=682 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00325] seq=8003, label=442 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00326] seq=10891, label=634 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00327] seq=9927, label=712 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00328] seq=5426, label=189 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00329] seq=8177, label=139 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00330] seq=7914, label=471 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00331] seq=9577, label=394 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00332] seq=9979, label=256 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00333] seq=7997, label=635 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00334] seq=2603, label=93 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00335] seq=8373, label=659 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00336] seq=5506, label=269 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00337] seq=4991, label=118 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00338] seq=3061, label=155 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00339] seq=6612, label=203 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00340] seq=2632, label=114 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00341] seq=9221, label=36 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00342] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00343] seq=2072, label=28 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9a5f59c0] mmco: unref short failure\n",
      "[h264 @ 0x9a5f59c0] mmco: unref short failure\n",
      "[h264 @ 0x9a5f59c0] mmco: unref short failure\n",
      "[h264 @ 0x9a5f59c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00344] seq=6067, label=525 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00345] seq=3239, label=172 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00346] seq=3985, label=116 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00347] seq=6973, label=350 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00348] seq=10566, label=479 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00349] seq=7246, label=34 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00350] seq=6219, label=230 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00351] seq=5754, label=643 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00352] seq=9694, label=160 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00353] seq=9844, label=229 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00354] seq=6488, label=210 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00355] seq=10891, label=732 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00356] seq=9321, label=58 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00357] seq=10913, label=669 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00358] seq=10357, label=465 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00359] seq=10338, label=374 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00360] seq=9807, label=334 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00361] seq=5189, label=181 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00362] seq=4363, label=110 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00363] seq=6339, label=470 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00364] seq=4879, label=229 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00365] seq=9438, label=316 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00366] seq=10935, label=645 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00367] seq=10701, label=478 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00368] seq=3479, label=102 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00369] seq=8848, label=578 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00370] seq=5811, label=169 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00371] seq=9532, label=603 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00372] seq=10875, label=740 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00373] seq=4439, label=183 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00374] seq=9595, label=247 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00375] seq=9325, label=141 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00376] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00377] seq=9690, label=291 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00378] seq=5466, label=321 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00379] seq=10958, label=626 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00380] seq=7991, label=258 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00381] seq=5547, label=281 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00382] seq=3891, label=37 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00383] seq=4217, label=254 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00384] seq=8257, label=560 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00385] seq=4385, label=52 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00386] seq=9495, label=96 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00387] seq=9246, label=705 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00388] seq=8205, label=305 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00389] seq=4875, label=252 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00390] seq=9969, label=292 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00391] seq=9847, label=259 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00392] seq=9383, label=42 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00393] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00394] seq=10607, label=700 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00395] seq=8422, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00396] seq=9639, label=679 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00397] seq=9230, label=47 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00398] seq=6747, label=70 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00399] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00400] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00401] seq=4596, label=170 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00402] seq=5032, label=67 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00403] seq=4673, label=149 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00404] seq=1597, label=28 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00405] seq=9608, label=175 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00406] seq=6922, label=405 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00407] seq=10967, label=660 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00408] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00409] seq=7561, label=506 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00410] seq=10968, label=675 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00411] seq=5831, label=359 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00412] seq=9508, label=76 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00413] seq=6703, label=931 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00414] seq=9839, label=203 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00415] seq=3012, label=245 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00416] seq=11054, label=549 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00417] seq=8762, label=578 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00418] seq=10947, label=682 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00419] seq=6817, label=283 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00420] seq=5086, label=820 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00421] seq=10668, label=628 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00422] seq=10911, label=603 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00423] seq=6555, label=91 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00424] seq=8480, label=408 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00425] seq=9412, label=102 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00426] seq=9439, label=84 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00427] seq=5728, label=352 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00428] seq=10031, label=679 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00429] seq=1786, label=71 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00430] seq=9391, label=403 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00431] seq=9422, label=585 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00432] seq=10567, label=646 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00433] seq=9968, label=317 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00434] seq=4400, label=371 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00435] seq=9861, label=446 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00436] seq=3787, label=211 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00437] seq=6273, label=438 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00438] seq=4432, label=81 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00439] seq=4252, label=73 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00440] seq=10407, label=473 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00441] seq=7116, label=255 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00442] seq=7041, label=230 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00443] seq=1869, label=28 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00444] seq=9363, label=40 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n",
      "[h264 @ 0x52e23980] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00445] seq=6177, label=336 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00446] seq=5424, label=921 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00447] seq=6505, label=268 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4973f540] mmco: unref short failure\n",
      "[h264 @ 0x4973f540] mmco: unref short failure\n",
      "[h264 @ 0x4973f540] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00448] seq=7127, label=291 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00449] seq=6435, label=119 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00450] seq=9764, label=579 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00451] seq=4781, label=55 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00452] seq=10919, label=704 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00453] seq=10386, label=539 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00454] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00455] seq=5321, label=251 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00456] seq=6582, label=108 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00457] seq=6166, label=70 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00458] seq=4527, label=293 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00459] seq=3992, label=166 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00460] seq=10021, label=341 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00461] seq=6661, label=712 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00462] seq=5231, label=75 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00463] seq=6050, label=239 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00464] seq=7219, label=689 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00465] seq=8577, label=234 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00466] seq=10837, label=594 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00467] seq=8203, label=339 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00468] seq=5831, label=124 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00469] seq=8612, label=544 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00470] seq=4746, label=180 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00471] seq=3273, label=311 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00472] seq=7115, label=74 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00473] seq=9830, label=212 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00474] seq=5937, label=108 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00475] seq=7460, label=158 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00476] seq=9645, label=183 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00477] seq=9233, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00478] seq=9575, label=171 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00479] seq=3580, label=104 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00480] seq=10128, label=398 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00481] seq=6605, label=227 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00482] seq=5914, label=87 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00483] seq=9547, label=202 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00484] seq=7722, label=947 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00485] seq=6536, label=451 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00486] seq=4789, label=68 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00487] seq=9950, label=329 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00488] seq=10000, label=316 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00489] seq=7946, label=355 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n",
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n",
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n",
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n",
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n",
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n",
      "[h264 @ 0x4a16bd40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00490] seq=10191, label=422 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00491] seq=10699, label=583 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00492] seq=10528, label=448 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00493] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00494] seq=7250, label=937 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00495] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00496] seq=8067, label=242 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00497] seq=5210, label=172 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00498] seq=5988, label=476 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00499] seq=10366, label=482 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00500] seq=1590, label=30 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00501] seq=3343, label=186 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00502] seq=3450, label=33 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00503] seq=10042, label=858 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00504] seq=4177, label=474 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00505] seq=7583, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00506] seq=6684, label=497 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00507] seq=4931, label=152 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00508] seq=3061, label=13 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00509] seq=10010, label=411 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00510] seq=10481, label=624 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00511] seq=2980, label=58 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49542a40] mmco: unref short failure\n",
      "[h264 @ 0x49542a40] mmco: unref short failure\n",
      "[h264 @ 0x49542a40] mmco: unref short failure\n",
      "[h264 @ 0x49542a40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00512] seq=10439, label=525 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00513] seq=10944, label=678 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00514] seq=6094, label=130 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00515] seq=4873, label=179 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00516] seq=1920, label=70 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00517] seq=2492, label=93 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00518] seq=7147, label=182 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00519] seq=7143, label=434 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49542a40] mmco: unref short failure\n",
      "[h264 @ 0x49542a40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00520] seq=9544, label=53 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00521] seq=10890, label=693 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00522] seq=8804, label=698 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00523] seq=5713, label=85 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n",
      "[h264 @ 0x486b01c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00524] seq=9464, label=77 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00525] seq=5470, label=277 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00526] seq=8787, label=352 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00527] seq=6214, label=317 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00528] seq=8952, label=414 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00529] seq=9154, label=102 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00530] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00531] seq=7910, label=155 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00532] seq=6098, label=139 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00533] seq=8018, label=581 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00534] seq=10867, label=658 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00535] seq=10344, label=428 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00536] seq=10518, label=497 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00537] seq=3878, label=239 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00538] seq=5053, label=188 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00539] seq=10247, label=458 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00540] seq=7241, label=28 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00541] seq=11079, label=576 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00542] seq=9540, label=362 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00543] seq=7115, label=315 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00544] seq=10962, label=650 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00545] seq=5649, label=289 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00546] seq=7182, label=229 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00547] seq=6738, label=370 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00548] seq=9624, label=668 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00549] seq=9524, label=119 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00550] seq=3305, label=42 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00551] seq=6244, label=638 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00552] seq=6162, label=191 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00553] seq=9064, label=463 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00554] seq=9785, label=694 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00555] seq=4993, label=202 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00556] seq=6256, label=41 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00557] seq=10896, label=624 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00558] seq=10429, label=550 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00559] seq=9826, label=265 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00560] seq=9352, label=55 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00561] seq=2915, label=188 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00562] seq=10827, label=638 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00563] seq=10179, label=389 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00564] seq=2600, label=54 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00565] seq=6480, label=407 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00566] seq=9566, label=266 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00567] seq=7041, label=279 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00568] seq=1330, label=46 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00569] seq=7170, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00570] seq=2871, label=92 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00571] seq=5713, label=420 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00572] seq=6773, label=295 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00573] seq=7624, label=287 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00574] seq=3473, label=80 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00575] seq=7187, label=142 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00576] seq=7149, label=334 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00577] seq=6910, label=291 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00578] seq=7409, label=63 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00579] seq=6247, label=211 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00580] seq=6944, label=154 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00581] seq=10945, label=620 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00582] seq=1762, label=27 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00583] seq=6833, label=417 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00584] seq=7823, label=393 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00585] seq=11036, label=611 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00586] seq=10923, label=694 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00587] seq=9529, label=326 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00588] seq=7100, label=630 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00589] seq=6674, label=322 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00590] seq=6118, label=239 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00591] seq=10402, label=562 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00592] seq=10180, label=606 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00593] seq=5196, label=360 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00594] seq=9746, label=562 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00595] seq=10835, label=652 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00596] seq=10943, label=660 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00597] seq=7270, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00598] seq=6928, label=404 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00599] seq=2507, label=61 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00600] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00601] seq=8724, label=171 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00602] seq=8676, label=95 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00603] seq=9859, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00604] seq=6748, label=340 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00605] seq=3126, label=70 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00606] seq=10118, label=335 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00607] seq=10431, label=508 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00608] seq=9869, label=235 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00609] seq=10255, label=360 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00610] seq=4881, label=403 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00611] seq=9882, label=554 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00612] seq=10248, label=1063 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00613] seq=9999, label=244 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00614] seq=9896, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00615] seq=5625, label=329 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00616] seq=4600, label=108 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00617] seq=9553, label=119 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x3cbded80] mmco: unref short failure\n",
      "[h264 @ 0x3cbded80] mmco: unref short failure\n",
      "[h264 @ 0x3cbded80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00618] seq=7221, label=117 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00619] seq=4625, label=75 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00620] seq=6343, label=527 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00621] seq=4655, label=61 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00622] seq=8831, label=595 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00623] seq=6577, label=176 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00624] seq=8516, label=791 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00625] seq=4018, label=233 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00626] seq=5592, label=408 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00627] seq=6020, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00628] seq=9851, label=666 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00629] seq=8960, label=46 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00630] seq=5025, label=240 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00631] seq=3036, label=110 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00632] seq=2750, label=110 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00633] seq=5509, label=292 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00634] seq=8952, label=1217 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00635] seq=7947, label=392 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00636] seq=10240, label=392 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00637] seq=10355, label=1176 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00638] seq=8539, label=316 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4976ef00] mmco: unref short failure\n",
      "[h264 @ 0x4976ef00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00639] seq=10591, label=586 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00640] seq=6196, label=170 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00641] seq=8237, label=547 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00642] seq=4620, label=243 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00643] seq=3341, label=84 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00644] seq=7153, label=223 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00645] seq=6971, label=395 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00646] seq=9900, label=723 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00647] seq=9348, label=171 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00648] seq=9346, label=615 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00649] seq=11045, label=586 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00650] seq=5516, label=230 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9c83b400] mmco: unref short failure\n",
      "[h264 @ 0x9c83b400] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00651] seq=4255, label=105 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00652] seq=10910, label=722 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00653] seq=6672, label=269 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00654] seq=3089, label=347 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00655] seq=9699, label=280 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00656] seq=3431, label=45 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00657] seq=4296, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00658] seq=10997, label=659 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00659] seq=6961, label=337 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00660] seq=10730, label=559 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00661] seq=4874, label=143 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00662] seq=10917, label=699 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00663] seq=7134, label=403 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00664] seq=7135, label=328 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00665] seq=11000, label=634 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00666] seq=9911, label=362 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00667] seq=10953, label=705 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00668] seq=10801, label=808 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00669] seq=8529, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00670] seq=3787, label=318 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00671] seq=8561, label=337 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00672] seq=9016, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00673] seq=11018, label=628 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00674] seq=7725, label=1042 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00675] seq=8175, label=120 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00676] seq=6298, label=294 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00677] seq=9791, label=165 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00678] seq=4933, label=117 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00679] seq=9765, label=682 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00680] seq=10914, label=713 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00681] seq=10761, label=485 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00682] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00683] seq=10984, label=581 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00684] seq=5758, label=419 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00685] seq=10940, label=665 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00686] seq=10759, label=559 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00687] seq=2053, label=54 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00688] seq=6437, label=252 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00689] seq=10588, label=418 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00690] seq=7689, label=450 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00691] seq=8462, label=323 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00692] seq=2363, label=72 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00693] seq=3819, label=45 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00694] seq=9433, label=55 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00695] seq=4698, label=595 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00696] seq=3498, label=260 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc433c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00697] seq=5786, label=104 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00698] seq=4798, label=259 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00699] seq=10293, label=414 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00700] seq=5878, label=74 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00701] seq=8454, label=332 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00702] seq=9222, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00703] seq=6859, label=312 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00704] seq=6299, label=226 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00705] seq=9486, label=123 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00706] seq=9209, label=25 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00707] seq=9875, label=697 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00708] seq=2403, label=279 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00709] seq=5865, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00710] seq=7988, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00711] seq=6450, label=183 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00712] seq=10780, label=689 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00713] seq=4711, label=477 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00714] seq=10039, label=363 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00715] seq=1653, label=136 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00716] seq=10289, label=355 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00717] seq=10332, label=498 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00718] seq=8806, label=338 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00719] seq=5507, label=132 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00720] seq=2962, label=31 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00721] seq=3756, label=92 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00722] seq=8358, label=570 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00723] seq=10921, label=708 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00724] seq=10004, label=292 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00725] seq=10966, label=663 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00726] seq=4619, label=52 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00727] seq=8403, label=255 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00728] seq=9482, label=66 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00729] seq=5319, label=168 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00730] seq=2340, label=95 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x6c5288c0] mmco: unref short failure\n",
      "[h264 @ 0x6c5288c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00731] seq=7277, label=189 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00732] seq=7746, label=460 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00733] seq=6790, label=118 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00734] seq=8306, label=658 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00735] seq=8634, label=1216 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00736] seq=10971, label=649 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00737] seq=9889, label=644 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00738] seq=9646, label=461 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00739] seq=4330, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00740] seq=8109, label=369 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00741] seq=3260, label=215 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00742] seq=7644, label=357 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00743] seq=7791, label=245 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00744] seq=9428, label=63 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00745] seq=10910, label=660 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00746] seq=10985, label=594 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00747] seq=9330, label=459 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00748] seq=1727, label=122 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00749] seq=5237, label=282 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00750] seq=5643, label=159 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00751] seq=2299, label=201 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00752] seq=10072, label=598 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00753] seq=9536, label=357 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00754] seq=11038, label=599 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00755] seq=9715, label=480 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00756] seq=9998, label=325 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00757] seq=4530, label=54 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00758] seq=7491, label=626 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00759] seq=3680, label=59 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00760] seq=8208, label=756 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00761] seq=4892, label=331 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00762] seq=5239, label=352 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00763] seq=7908, label=148 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00764] seq=9378, label=1048 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00765] seq=5756, label=193 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00766] seq=10848, label=729 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00767] seq=6664, label=367 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00768] seq=10325, label=418 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00769] seq=9851, label=217 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00770] seq=6057, label=407 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00771] seq=7842, label=594 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x740aaa00] mmco: unref short failure\n",
      "[h264 @ 0x740aaa00] mmco: unref short failure\n",
      "[h264 @ 0x740aaa00] mmco: unref short failure\n",
      "[h264 @ 0x740aaa00] mmco: unref short failure\n",
      "[h264 @ 0x740aaa00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00772] seq=8052, label=687 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00773] seq=7173, label=273 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00774] seq=8162, label=168 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00775] seq=7179, label=343 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00776] seq=11023, label=606 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00777] seq=5249, label=573 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00778] seq=3497, label=102 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00779] seq=8293, label=346 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00780] seq=10067, label=888 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00781] seq=6725, label=1042 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00782] seq=4089, label=262 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00783] seq=11016, label=611 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00784] seq=10984, label=637 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00785] seq=10891, label=699 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00786] seq=2789, label=118 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00787] seq=8756, label=754 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00788] seq=1450, label=117 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00789] seq=6241, label=458 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00790] seq=10943, label=626 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00791] seq=10128, label=334 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00792] seq=5797, label=302 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00793] seq=2217, label=164 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00794] seq=10118, label=303 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00795] seq=3006, label=109 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00796] seq=7125, label=351 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00797] seq=9946, label=279 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00798] seq=9625, label=386 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00799] seq=10439, label=443 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00800] seq=10156, label=694 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00801] seq=7650, label=39 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00802] seq=4963, label=346 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00803] seq=7654, label=101 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00804] seq=9574, label=162 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00805] seq=10962, label=675 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00806] seq=10263, label=340 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00807] seq=3092, label=548 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00808] seq=4490, label=167 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00809] seq=3235, label=80 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00810] seq=7562, label=90 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00811] seq=8090, label=80 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00812] seq=6671, label=335 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00813] seq=7830, label=857 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00814] seq=6672, label=221 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00815] seq=6307, label=429 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00816] seq=9358, label=142 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00817] seq=10909, label=719 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00818] seq=3961, label=212 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00819] seq=4487, label=170 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49725b80] mmco: unref short failure\n",
      "[h264 @ 0x49725b80] mmco: unref short failure\n",
      "[h264 @ 0x49725b80] mmco: unref short failure\n",
      "[h264 @ 0x49725b80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00820] seq=10315, label=688 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00821] seq=10981, label=640 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00822] seq=4900, label=275 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00823] seq=9905, label=395 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00824] seq=9847, label=234 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00825] seq=7873, label=715 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00826] seq=6505, label=104 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00827] seq=5731, label=218 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00828] seq=3449, label=78 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00829] seq=11014, label=603 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00830] seq=6098, label=85 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00831] seq=9855, label=348 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00832] seq=5856, label=358 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00833] seq=4846, label=104 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00834] seq=6438, label=121 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00835] seq=10884, label=617 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00836] seq=6173, label=89 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00837] seq=2313, label=211 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00838] seq=10082, label=898 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00839] seq=10613, label=625 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00840] seq=10955, label=639 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00841] seq=3314, label=576 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x22cc4b00] mmco: unref short failure\n",
      "[h264 @ 0x22cc4b00] mmco: unref short failure\n",
      "[h264 @ 0x22cc4b00] mmco: unref short failure\n",
      "[h264 @ 0x22cc4b00] mmco: unref short failure\n",
      "[h264 @ 0x22cc4b00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00842] seq=10149, label=401 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00843] seq=5597, label=295 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00844] seq=7540, label=437 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00845] seq=3914, label=146 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00846] seq=4485, label=134 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00847] seq=6341, label=315 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00848] seq=9967, label=319 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00849] seq=9337, label=88 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00850] seq=5076, label=263 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00851] seq=1845, label=14 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00852] seq=10222, label=312 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00853] seq=3343, label=179 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00854] seq=4554, label=306 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00855] seq=9445, label=319 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00856] seq=5358, label=366 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00857] seq=6211, label=716 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00858] seq=8568, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00859] seq=8433, label=104 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00860] seq=9919, label=281 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00861] seq=1443, label=163 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00862] seq=8241, label=523 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00863] seq=7088, label=284 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00864] seq=2192, label=70 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00865] seq=9903, label=347 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00866] seq=9722, label=537 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00867] seq=8457, label=675 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00868] seq=6125, label=261 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00869] seq=10103, label=309 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00870] seq=10171, label=766 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00871] seq=10160, label=440 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00872] seq=11031, label=618 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00873] seq=8546, label=215 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00874] seq=1330, label=15 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4a26c500] mmco: unref short failure\n",
      "[h264 @ 0x4a26c500] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00875] seq=8941, label=423 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00876] seq=6689, label=674 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00877] seq=6736, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x498f5480] mmco: unref short failure\n",
      "[h264 @ 0x498f5480] mmco: unref short failure\n",
      "[h264 @ 0x498f5480] mmco: unref short failure\n",
      "[h264 @ 0x498f5480] mmco: unref short failure\n",
      "[h264 @ 0x498f5480] mmco: unref short failure\n",
      "[h264 @ 0x498f5480] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00878] seq=10291, label=497 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00879] seq=8356, label=649 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00880] seq=10128, label=401 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00881] seq=6319, label=333 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00882] seq=5591, label=679 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00883] seq=3504, label=47 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00884] seq=3066, label=123 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00885] seq=9517, label=1014 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00886] seq=2254, label=141 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00887] seq=2679, label=104 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00888] seq=10647, label=579 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00889] seq=6623, label=679 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00890] seq=5027, label=72 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00891] seq=8663, label=205 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00892] seq=5725, label=219 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00893] seq=6678, label=215 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00894] seq=6175, label=371 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00895] seq=6116, label=417 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00896] seq=4718, label=243 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00897] seq=8796, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00898] seq=10881, label=694 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00899] seq=10225, label=1048 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00900] seq=5577, label=399 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00901] seq=9561, label=382 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00902] seq=5250, label=315 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00903] seq=2595, label=136 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00904] seq=4788, label=347 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00905] seq=8285, label=647 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00906] seq=4402, label=227 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00907] seq=10863, label=694 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00908] seq=6108, label=348 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00909] seq=3412, label=209 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00910] seq=8085, label=389 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00911] seq=9837, label=344 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00912] seq=5955, label=892 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00913] seq=10111, label=252 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00914] seq=5420, label=94 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00915] seq=10970, label=646 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00916] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00917] seq=9570, label=501 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00918] seq=4515, label=383 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00919] seq=10972, label=654 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00920] seq=6852, label=352 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00921] seq=4449, label=207 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00922] seq=10779, label=616 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00923] seq=10229, label=605 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00924] seq=6613, label=332 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00925] seq=5810, label=209 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00926] seq=9826, label=316 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4976ef00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00927] seq=6874, label=526 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00928] seq=6001, label=228 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00929] seq=8971, label=274 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00930] seq=10791, label=679 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00931] seq=2672, label=138 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00932] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00933] seq=5165, label=428 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00934] seq=10171, label=572 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00935] seq=4036, label=594 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00936] seq=10961, label=636 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00937] seq=9974, label=250 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00938] seq=7826, label=173 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00939] seq=7251, label=386 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00940] seq=7203, label=109 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00941] seq=10639, label=671 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00942] seq=2882, label=156 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00943] seq=8652, label=457 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00944] seq=9705, label=266 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00945] seq=5119, label=188 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00946] seq=7611, label=655 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00947] seq=5905, label=82 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00948] seq=9707, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00949] seq=6609, label=380 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00950] seq=5655, label=202 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00951] seq=7209, label=131 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00952] seq=5112, label=101 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00953] seq=6915, label=293 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00954] seq=7999, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00955] seq=10984, label=578 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00956] seq=3066, label=89 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00957] seq=4693, label=385 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00958] seq=10611, label=537 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00959] seq=4621, label=73 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00960] seq=5037, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00961] seq=9556, label=142 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00962] seq=3750, label=196 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00963] seq=3443, label=121 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00964] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00965] seq=5861, label=240 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00966] seq=8907, label=571 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00967] seq=10894, label=720 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00968] seq=10996, label=633 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00969] seq=10429, label=332 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00970] seq=9605, label=420 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00971] seq=10968, label=673 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00972] seq=10956, label=675 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00973] seq=8609, label=602 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00974] seq=9651, label=226 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00975] seq=8359, label=250 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00976] seq=4299, label=108 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00977] seq=8890, label=395 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00978] seq=6208, label=182 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00979] seq=5904, label=812 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00980] seq=5161, label=167 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00981] seq=6621, label=57 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00982] seq=2826, label=112 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00983] seq=9822, label=640 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00984] seq=4594, label=406 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00985] seq=10931, label=672 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00986] seq=9431, label=155 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00987] seq=7329, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00988] seq=6830, label=239 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4976ef00] mmco: unref short failure\n",
      "[h264 @ 0x4976ef00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 00989] seq=1973, label=222 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00990] seq=10139, label=300 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00991] seq=9413, label=514 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00992] seq=10592, label=667 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00993] seq=2929, label=27 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00994] seq=7864, label=507 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00995] seq=10955, label=668 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00996] seq=10027, label=478 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00997] seq=5859, label=100 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00998] seq=3770, label=187 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 00999] seq=10888, label=725 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01000] seq=8500, label=112 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01001] seq=10145, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01002] seq=4658, label=291 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x47b62100] Missing reference picture, default is 65530\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x47b62100] Missing reference picture, default is 65530\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01003] seq=6909, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01004] seq=7531, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01005] seq=9733, label=269 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01006] seq=6087, label=229 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01007] seq=9247, label=65 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01008] seq=7515, label=331 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01009] seq=6535, label=537 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01010] seq=7260, label=972 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01011] seq=5237, label=539 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01012] seq=3451, label=107 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01013] seq=2982, label=112 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01014] seq=3524, label=176 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01015] seq=6344, label=458 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01016] seq=10901, label=754 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01017] seq=10389, label=427 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01018] seq=9749, label=751 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01019] seq=9667, label=81 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01020] seq=6092, label=232 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01021] seq=8566, label=220 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01022] seq=9891, label=214 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01023] seq=10156, label=470 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01024] seq=6217, label=909 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01025] seq=8706, label=921 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01026] seq=7778, label=163 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01027] seq=6456, label=96 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01028] seq=4985, label=217 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01029] seq=4760, label=281 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01030] seq=5911, label=41 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01031] seq=9044, label=371 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01032] seq=7828, label=251 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01033] seq=10937, label=662 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01034] seq=5443, label=779 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01035] seq=10461, label=476 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01036] seq=5774, label=335 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01037] seq=9867, label=375 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01038] seq=10689, label=749 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01039] seq=8946, label=208 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01040] seq=9821, label=173 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01041] seq=9316, label=494 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x4a15a2c0] mmco: unref short failure\n",
      "[h264 @ 0x4a15a2c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01042] seq=5903, label=355 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01043] seq=5945, label=430 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01044] seq=9679, label=189 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01045] seq=5834, label=77 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01046] seq=7092, label=190 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01047] seq=3188, label=334 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49732380] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01048] seq=8214, label=409 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01049] seq=10881, label=772 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01050] seq=9450, label=202 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01051] seq=2771, label=229 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01052] seq=8414, label=87 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01053] seq=5087, label=91 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9b2b7c00] mmco: unref short failure\n",
      "[h264 @ 0x9b2b7c00] mmco: unref short failure\n",
      "[h264 @ 0x9b2b7c00] mmco: unref short failure\n",
      "[h264 @ 0x9b2b7c00] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01054] seq=6479, label=401 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01055] seq=4731, label=246 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01056] seq=4767, label=230 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01057] seq=4548, label=32 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01058] seq=8190, label=430 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01059] seq=7380, label=442 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01060] seq=9418, label=440 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01061] seq=9017, label=616 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x54ea5340] mmco: unref short failure\n",
      "[h264 @ 0x54ea5340] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01062] seq=3840, label=230 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01063] seq=10860, label=773 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01064] seq=9402, label=100 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01065] seq=5533, label=325 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01066] seq=8954, label=496 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01067] seq=5913, label=593 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01068] seq=3279, label=42 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01069] seq=2462, label=56 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01070] seq=8555, label=596 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01071] seq=5591, label=73 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01072] seq=7651, label=331 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc18700] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01073] seq=10130, label=290 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01074] seq=4636, label=179 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01075] seq=5746, label=65 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01076] seq=5015, label=168 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01077] seq=10260, label=362 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01078] seq=10188, label=351 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01079] seq=3812, label=70 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01080] seq=6386, label=569 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01081] seq=9855, label=670 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01082] seq=5821, label=136 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01083] seq=1962, label=100 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01084] seq=7618, label=450 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01085] seq=10537, label=598 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01086] seq=10922, label=666 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01087] seq=8342, label=42 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01088] seq=4188, label=168 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01089] seq=8892, label=560 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01090] seq=10538, label=553 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01091] seq=6737, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01092] seq=4728, label=68 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01093] seq=6838, label=56 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01094] seq=7290, label=1116 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01095] seq=10459, label=356 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01096] seq=7149, label=196 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01097] seq=7999, label=630 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01098] seq=1821, label=14 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01099] seq=8318, label=167 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01100] seq=8678, label=423 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01101] seq=6181, label=395 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01102] seq=7574, label=93 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01103] seq=6638, label=134 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01104] seq=10840, label=479 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01105] seq=10102, label=924 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01106] seq=7874, label=263 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01107] seq=10222, label=628 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01108] seq=2382, label=153 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01109] seq=5859, label=248 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01110] seq=10333, label=622 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01111] seq=10082, label=343 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01112] seq=2471, label=13 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01113] seq=5832, label=296 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01114] seq=7785, label=82 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01115] seq=9672, label=256 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01116] seq=8732, label=717 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01117] seq=5761, label=260 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01118] seq=8440, label=383 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01119] seq=5122, label=460 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01120] seq=1934, label=235 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01121] seq=6769, label=244 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01122] seq=5467, label=230 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01123] seq=5098, label=105 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01124] seq=7130, label=119 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01125] seq=10902, label=683 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01126] seq=4103, label=69 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01127] seq=7718, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01128] seq=4954, label=239 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01129] seq=7287, label=421 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01130] seq=6033, label=257 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01131] seq=2859, label=227 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01132] seq=10889, label=500 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01133] seq=10141, label=472 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01134] seq=9125, label=94 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01135] seq=5466, label=99 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01136] seq=6142, label=212 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01137] seq=9314, label=377 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01138] seq=10331, label=427 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01139] seq=5637, label=222 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x50489480] mmco: unref short failure\n",
      "[h264 @ 0x50489480] mmco: unref short failure\n",
      "[h264 @ 0x50489480] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01140] seq=10129, label=758 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01141] seq=8776, label=353 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01142] seq=10462, label=466 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01143] seq=8628, label=447 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01144] seq=3716, label=283 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01145] seq=10979, label=595 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01146] seq=6193, label=398 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01147] seq=6501, label=606 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01148] seq=7866, label=511 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n",
      "[h264 @ 0x49739900] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01149] seq=2032, label=240 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01150] seq=5606, label=392 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01151] seq=9679, label=496 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01152] seq=11018, label=568 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01153] seq=9427, label=105 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01154] seq=8721, label=671 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01155] seq=10786, label=629 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01156] seq=9970, label=315 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01157] seq=4729, label=203 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01158] seq=4740, label=138 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01159] seq=9936, label=309 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01160] seq=11000, label=562 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01161] seq=8958, label=445 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01162] seq=10258, label=492 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01163] seq=9751, label=254 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01164] seq=7368, label=348 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01165] seq=8563, label=28 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01166] seq=3377, label=60 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01167] seq=6342, label=314 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01168] seq=9407, label=160 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01169] seq=3274, label=99 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01170] seq=10198, label=275 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01171] seq=1393, label=48 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01172] seq=10097, label=403 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01173] seq=7519, label=77 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01174] seq=5189, label=353 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01175] seq=9485, label=547 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01176] seq=4749, label=211 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01177] seq=3709, label=471 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01178] seq=7036, label=222 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01179] seq=5003, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01180] seq=9142, label=200 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01181] seq=3294, label=72 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01182] seq=3331, label=325 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01183] seq=2830, label=52 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01184] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01185] seq=4216, label=164 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01186] seq=7362, label=240 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01187] seq=10941, label=644 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01188] seq=7797, label=636 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01189] seq=3782, label=99 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01190] seq=9484, label=208 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01191] seq=10368, label=630 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01192] seq=8108, label=72 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01193] seq=10502, label=561 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01194] seq=6536, label=68 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01195] seq=6512, label=204 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01196] seq=5399, label=522 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01197] seq=6495, label=37 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01198] seq=8666, label=32 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01199] seq=7493, label=446 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01200] seq=6223, label=75 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01201] seq=6693, label=727 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01202] seq=10120, label=329 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01203] seq=3552, label=118 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01204] seq=6879, label=1010 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01205] seq=9163, label=358 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01206] seq=6886, label=358 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01207] seq=5990, label=129 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01208] seq=3896, label=59 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01209] seq=7003, label=148 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01210] seq=10922, label=714 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01211] seq=3500, label=161 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01212] seq=6137, label=408 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01213] seq=10934, label=649 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01214] seq=1706, label=48 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01215] seq=10087, label=485 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01216] seq=6288, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01217] seq=1393, label=73 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01218] seq=2413, label=300 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01219] seq=10958, label=649 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01220] seq=7588, label=195 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01221] seq=10102, label=600 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01222] seq=6385, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01223] seq=9649, label=245 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01224] seq=8273, label=714 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01225] seq=3957, label=183 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01226] seq=1793, label=101 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01227] seq=1428, label=42 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01228] seq=7236, label=453 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01229] seq=5984, label=451 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01230] seq=5489, label=299 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01231] seq=6834, label=116 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01232] seq=3075, label=91 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01233] seq=5810, label=83 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01234] seq=8803, label=1055 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01235] seq=5390, label=323 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01236] seq=10195, label=391 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01237] seq=10758, label=859 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01238] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01239] seq=9628, label=134 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01240] seq=4991, label=251 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01241] seq=9825, label=344 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01242] seq=4172, label=258 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01243] seq=9227, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01244] seq=9336, label=120 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01245] seq=7180, label=571 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01246] seq=5743, label=113 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01247] seq=5937, label=619 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01248] seq=7567, label=773 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01249] seq=4045, label=323 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01250] seq=6578, label=634 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01251] seq=9561, label=382 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01252] seq=9892, label=707 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01253] seq=7394, label=105 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01254] seq=6161, label=413 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01255] seq=6212, label=479 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01256] seq=7028, label=350 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01257] seq=6765, label=159 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01258] seq=10089, label=394 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01259] seq=9559, label=375 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01260] seq=10984, label=613 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01261] seq=7414, label=236 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01262] seq=3370, label=93 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01263] seq=10582, label=513 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01264] seq=9328, label=784 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01265] seq=5268, label=152 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01266] seq=9375, label=159 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01267] seq=10865, label=703 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01268] seq=6600, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01269] seq=7776, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01270] seq=3334, label=80 | video=19x16x16=4864 | audio=30000 | CUDA alloc=3333.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01271] seq=10312, label=618 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01272] seq=5214, label=302 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01273] seq=10996, label=617 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01274] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01275] seq=4619, label=250 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01276] seq=8061, label=307 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01277] seq=10967, label=689 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01278] seq=6951, label=139 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01279] seq=7134, label=169 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01280] seq=10112, label=304 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01281] seq=10941, label=680 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01282] seq=6515, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01283] seq=5305, label=170 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01284] seq=7163, label=189 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01285] seq=2000, label=93 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01286] seq=10881, label=687 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01287] seq=10855, label=724 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01288] seq=10237, label=448 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01289] seq=10754, label=620 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01290] seq=4115, label=47 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01291] seq=8316, label=999 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01292] seq=9026, label=574 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01293] seq=10324, label=383 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01294] seq=10967, label=630 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01295] seq=7069, label=335 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01296] seq=10036, label=333 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01297] seq=5624, label=865 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01298] seq=6707, label=475 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01299] seq=6686, label=241 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01300] seq=9780, label=403 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01301] seq=5706, label=476 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01302] seq=9390, label=176 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01303] seq=9379, label=162 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01304] seq=5445, label=391 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01305] seq=1917, label=123 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01306] seq=5877, label=126 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01307] seq=9981, label=876 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01308] seq=2174, label=70 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01309] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01310] seq=6034, label=204 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01311] seq=5775, label=383 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01312] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01313] seq=2540, label=61 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01314] seq=10875, label=700 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01315] seq=2938, label=150 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01316] seq=10267, label=461 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01317] seq=5520, label=82 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x54cae5c0] mmco: unref short failure\n",
      "[h264 @ 0x54cae5c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01318] seq=9374, label=262 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01319] seq=6722, label=290 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01320] seq=10090, label=366 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01321] seq=9162, label=243 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01322] seq=4153, label=224 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01323] seq=3359, label=246 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01324] seq=7307, label=743 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01325] seq=10268, label=444 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01326] seq=6080, label=426 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01327] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01328] seq=6607, label=45 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01329] seq=10024, label=276 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01330] seq=9820, label=297 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01331] seq=5937, label=32 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01332] seq=4824, label=61 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01333] seq=10047, label=283 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01334] seq=2737, label=73 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01335] seq=9802, label=234 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01336] seq=5964, label=120 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01337] seq=5918, label=70 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9a538980] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01338] seq=10731, label=490 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01339] seq=6240, label=175 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01340] seq=10786, label=585 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01341] seq=10110, label=361 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01342] seq=5552, label=563 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01343] seq=5083, label=309 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01344] seq=4718, label=519 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01345] seq=2744, label=94 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01346] seq=9721, label=1116 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01347] seq=6691, label=873 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01348] seq=4870, label=623 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01349] seq=5754, label=484 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01350] seq=10059, label=875 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01351] seq=5533, label=371 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01352] seq=5497, label=177 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01353] seq=9936, label=347 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01354] seq=6612, label=199 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01355] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01356] seq=8682, label=815 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n",
      "[h264 @ 0x9dc18700] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01357] seq=3712, label=171 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01358] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01359] seq=10894, label=759 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01360] seq=5583, label=143 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01361] seq=5527, label=187 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01362] seq=5915, label=81 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n",
      "[h264 @ 0x49732380] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01363] seq=6299, label=868 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01364] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01365] seq=9945, label=395 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01366] seq=10972, label=670 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01367] seq=5644, label=597 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01368] seq=4050, label=27 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01369] seq=8043, label=421 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01370] seq=8169, label=28 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01371] seq=7976, label=565 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01372] seq=10996, label=626 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01373] seq=10712, label=629 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01374] seq=7161, label=85 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01375] seq=2778, label=41 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01376] seq=10974, label=683 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01377] seq=5724, label=148 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01378] seq=3963, label=210 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01379] seq=6208, label=194 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01380] seq=10583, label=535 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01381] seq=8089, label=84 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01382] seq=10016, label=284 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n",
      "[h264 @ 0x47fcaf40] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01383] seq=5398, label=411 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01384] seq=4694, label=278 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01385] seq=3857, label=240 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01386] seq=6178, label=932 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01387] seq=10857, label=761 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01388] seq=2745, label=28 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x50481880] mmco: unref short failure\n",
      "[h264 @ 0x50481880] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01389] seq=9359, label=130 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01390] seq=4707, label=330 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01391] seq=7575, label=430 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01392] seq=6229, label=1014 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01393] seq=9426, label=126 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01394] seq=10708, label=575 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01395] seq=3326, label=232 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01396] seq=6137, label=735 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01397] seq=10198, label=440 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01398] seq=5964, label=95 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01399] seq=3786, label=47 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01400] seq=4496, label=172 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01401] seq=6063, label=71 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01402] seq=10948, label=654 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01403] seq=2125, label=13 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01404] seq=10478, label=385 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01405] seq=10401, label=465 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01406] seq=4102, label=134 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01407] seq=5860, label=754 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01408] seq=2251, label=90 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01409] seq=6760, label=371 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01410] seq=10065, label=886 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01411] seq=7234, label=464 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01412] seq=6706, label=165 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9a6046c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01413] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01414] seq=10370, label=1192 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01415] seq=10783, label=587 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01416] seq=1568, label=146 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01417] seq=9484, label=669 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01418] seq=2813, label=160 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01419] seq=6011, label=203 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01420] seq=7031, label=467 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01421] seq=10559, label=485 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01422] seq=6572, label=423 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01423] seq=9395, label=626 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01424] seq=3813, label=78 | video=21x16x16=5376 | audio=30000 | CUDA alloc=3335.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01425] seq=6430, label=1123 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01426] seq=2623, label=148 | video=13x16x16=3328 | audio=30000 | CUDA alloc=3326.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01427] seq=9671, label=335 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01428] seq=6893, label=25 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01429] seq=10888, label=693 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01430] seq=9455, label=276 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01431] seq=7029, label=412 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01432] seq=9826, label=351 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01433] seq=1688, label=89 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01434] seq=1439, label=55 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01435] seq=3614, label=226 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01436] seq=2789, label=214 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01437] seq=9960, label=283 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01438] seq=1474, label=160 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01439] seq=6489, label=276 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01440] seq=9767, label=270 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01441] seq=2092, label=98 | video=11x16x16=2816 | audio=30000 | CUDA alloc=3323.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01442] seq=5221, label=580 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x52f55900] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01443] seq=6772, label=943 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01444] seq=5600, label=448 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01445] seq=10841, label=580 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01446] seq=10902, label=745 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01447] seq=9236, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01448] seq=4047, label=39 | video=23x16x16=5888 | audio=30000 | CUDA alloc=3337.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01449] seq=8226, label=15 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01450] seq=4055, label=93 | video=22x16x16=5632 | audio=30000 | CUDA alloc=3336.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01451] seq=7471, label=366 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01452] seq=9258, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01453] seq=9696, label=292 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01454] seq=10338, label=410 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01455] seq=9814, label=411 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01456] seq=6363, label=371 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01457] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01458] seq=8581, label=707 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01459] seq=3213, label=321 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01460] seq=11001, label=576 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01461] seq=6387, label=269 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01462] seq=7686, label=126 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01463] seq=4901, label=280 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01464] seq=5482, label=241 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01465] seq=7781, label=172 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01466] seq=3173, label=117 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01467] seq=3482, label=185 | video=17x16x16=4352 | audio=30000 | CUDA alloc=3330.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01468] seq=10766, label=687 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01469] seq=10327, label=1144 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01470] seq=10107, label=472 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01471] seq=4702, label=322 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01472] seq=3627, label=92 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01473] seq=7730, label=118 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01474] seq=3744, label=179 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01475] seq=5003, label=94 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01476] seq=10917, label=619 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01477] seq=9037, label=673 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01478] seq=10224, label=409 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01479] seq=10843, label=739 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01480] seq=9387, label=70 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01481] seq=3673, label=104 | video=20x16x16=5120 | audio=30000 | CUDA alloc=3334.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01482] seq=4890, label=100 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01483] seq=6366, label=258 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01484] seq=8152, label=543 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01485] seq=8032, label=776 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01486] seq=10414, label=543 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01487] seq=7496, label=558 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01488] seq=3438, label=368 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01489] seq=10066, label=365 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01490] seq=10970, label=547 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01491] seq=4573, label=66 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01492] seq=9433, label=152 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01493] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01494] seq=2640, label=97 | video=14x16x16=3584 | audio=30000 | CUDA alloc=3327.2MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01495] seq=5912, label=301 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01496] seq=4594, label=233 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01497] seq=5635, label=573 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01498] seq=7000, label=435 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01499] seq=5359, label=176 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01500] seq=9043, label=114 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01501] seq=6343, label=268 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01502] seq=9653, label=142 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01503] seq=6203, label=204 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01504] seq=10877, label=612 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01505] seq=9679, label=267 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01506] seq=4636, label=287 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01507] seq=9882, label=523 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01508] seq=5132, label=228 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01509] seq=6163, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01510] seq=10033, label=849 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01511] seq=10925, label=666 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01512] seq=5739, label=596 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01513] seq=6131, label=364 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01514] seq=7647, label=338 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01515] seq=10866, label=722 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01516] seq=11003, label=618 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01517] seq=9708, label=529 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01518] seq=10946, label=687 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01519] seq=3409, label=159 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01520] seq=6391, label=491 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01521] seq=4702, label=60 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01522] seq=9521, label=77 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01523] seq=9453, label=172 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01524] seq=5141, label=194 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01525] seq=10879, label=726 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01526] seq=6425, label=453 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01527] seq=1352, label=14 | video=7x16x16=1792 | audio=30000 | CUDA alloc=3319.1MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01528] seq=5637, label=583 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01529] seq=7358, label=412 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01530] seq=10895, label=697 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01531] seq=8145, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x2be983c0] mmco: unref short failure\n",
      "[h264 @ 0x2be983c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01532] seq=9338, label=330 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01533] seq=6540, label=150 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01534] seq=4987, label=227 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01535] seq=7773, label=473 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01536] seq=9345, label=412 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01537] seq=10000, label=649 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01538] seq=9244, label=13 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01539] seq=1719, label=100 | video=9x16x16=2304 | audio=30000 | CUDA alloc=3321.4MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01540] seq=6268, label=279 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01541] seq=7741, label=617 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01542] seq=10736, label=560 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x497da980] mmco: unref short failure\n",
      "[h264 @ 0x497da980] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01543] seq=6763, label=84 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01544] seq=5868, label=357 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01545] seq=11000, label=570 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01546] seq=4469, label=82 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01547] seq=9609, label=145 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01548] seq=9656, label=238 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01549] seq=7149, label=281 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01550] seq=1891, label=165 | video=10x16x16=2560 | audio=30000 | CUDA alloc=3322.6MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01551] seq=10643, label=552 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01552] seq=4782, label=116 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01553] seq=8928, label=1131 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01554] seq=4999, label=77 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01555] seq=10803, label=693 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01556] seq=11009, label=648 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01557] seq=4500, label=183 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01558] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01559] seq=5009, label=72 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01560] seq=4618, label=207 | video=24x16x16=6144 | audio=30000 | CUDA alloc=3338.7MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01561] seq=6654, label=333 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01562] seq=5582, label=304 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01563] seq=9824, label=369 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01564] seq=5000, label=160 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01565] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01566] seq=2666, label=128 | video=15x16x16=3840 | audio=30000 | CUDA alloc=3328.3MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01567] seq=10409, label=1225 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01568] seq=1528, label=14 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dbb54c0] mmco: unref short failure\n",
      "[h264 @ 0x9dbb54c0] mmco: unref short failure\n",
      "[h264 @ 0x9dbb54c0] mmco: unref short failure\n",
      "[h264 @ 0x9dbb54c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01569] seq=5476, label=349 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01570] seq=10256, label=560 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01571] seq=4872, label=52 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01572] seq=6587, label=145 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01573] seq=9149, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01574] seq=2277, label=185 | video=12x16x16=3072 | audio=30000 | CUDA alloc=3324.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01575] seq=9900, label=213 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01576] seq=7564, label=224 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01577] seq=10155, label=268 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01578] seq=10957, label=667 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01579] seq=10821, label=722 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01580] seq=5312, label=14 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01581] seq=4478, label=78 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01582] seq=10928, label=663 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01583] seq=5903, label=671 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01584] seq=8498, label=655 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01585] seq=9745, label=250 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01586] seq=10872, label=703 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x9dbb54c0] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01587] seq=10929, label=653 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01588] seq=10223, label=362 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01589] seq=6761, label=0 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01590] seq=7235, label=297 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01591] seq=8726, label=652 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01592] seq=10738, label=500 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01593] seq=10977, label=664 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01594] seq=5207, label=66 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01595] seq=3454, label=248 | video=16x16x16=4096 | audio=30000 | CUDA alloc=3329.5MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01596] seq=10961, label=675 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01597] seq=9475, label=200 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01598] seq=6775, label=325 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01599] seq=9643, label=464 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01600] seq=5939, label=172 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01601] seq=4738, label=168 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01602] seq=10420, label=566 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01603] seq=9963, label=778 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01604] seq=4702, label=169 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01605] seq=5243, label=145 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01606] seq=8956, label=69 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01607] seq=5137, label=203 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01608] seq=9502, label=193 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01609] seq=6511, label=263 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01610] seq=10274, label=428 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01611] seq=9205, label=595 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01612] seq=6813, label=73 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01613] seq=3425, label=378 | video=18x16x16=4608 | audio=30000 | CUDA alloc=3331.8MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x740a5f80] mmco: unref short failure\n",
      "[h264 @ 0x740a5f80] mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 01614] seq=10894, label=693 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01615] seq=10934, label=656 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01616] seq=10552, label=536 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01617] seq=9627, label=128 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01618] seq=9324, label=79 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3340.0MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01619] seq=5254, label=311 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01620] seq=4492, label=111 | video=25x16x16=6400 | audio=30000 | CUDA alloc=3339.9MB peak=13107.2MB reserve=13826.0MB\n",
      "[Step 01621] seq=1617, label=160 | video=8x16x16=2048 | audio=30000 | CUDA alloc=3320.3MB peak=13107.2MB reserve=13826.0MB\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

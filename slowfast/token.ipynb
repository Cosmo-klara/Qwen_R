{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b9c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda120a3",
   "metadata": {},
   "source": [
    "只在 visual encoder + MLP/linear 得到的 [T, N_patch, D_llm] image_features (T, N, D) 上做处理\n",
    "\n",
    "[T, C, H, W] - [T, N_patch, D_vision] - [T, N_patch, D_llm]\n",
    "\n",
    "- slow 通路：\n",
    "\n",
    "\n",
    "\n",
    "- fast 通路：\n",
    "\n",
    "\n",
    "\n",
    "- slow_fast 拼接：\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9008035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SlowFastConfig:\n",
    "    # slow\n",
    "    slow_num_frames: int = 8\n",
    "    slow_spatial_pool: str = \"1d_max\"   # \"1d_max\" | \"1d_avg\" | \"none\"\n",
    "\n",
    "    # fast\n",
    "    fast_spatial_size: int = 4          # e.g. 4 → 4x4\n",
    "\n",
    "    assume_square_patches: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6827b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import math\n",
    "\n",
    "class SlowFastConfig:\n",
    "    def __init__(self, slow_num_frames=8, slow_spatial_pool=\"1d_max\", fast_output_size=(4,4)):\n",
    "        self.slow_num_frames = slow_num_frames\n",
    "        self.slow_spatial_pool = slow_spatial_pool\n",
    "        self.fast_output_size = fast_output_size\n",
    "\n",
    "class TokenSlowFastAggregator(nn.Module):\n",
    "    def __init__(self, cfg: SlowFastConfig, num_patches_per_side: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.H = num_patches_per_side # ViT 每帧的 patch 网格大小 H*H\n",
    "\n",
    "    def forward(self, x, debug=False):\n",
    "        T, N, D = x.shape\n",
    "        H = self.H\n",
    "        assert N == H*H, f\"[SlowFast] N={N} not equal to ViT grid H^2={H*H}\"\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        # Slow\n",
    "        slow_T = min(T, self.cfg.slow_num_frames)\n",
    "        slow_idx = torch.linspace(0, T-1, slow_T).long()\n",
    "        slow_x = x[slow_idx]  # (T_s, N, D)\n",
    "\n",
    "        # if self.cfg.slow_spatial_pool == \"1d_max\":\n",
    "        #     # 将每两个 token 做 max pool -> token 数量减半\n",
    "        #     slow_x = slow_x.reshape(slow_T, -1, 2, D).max(dim=2).values  # (T_s, N//2, D)\n",
    "        # elif self.cfg.slow_spatial_pool == \"1d_avg\":\n",
    "        #     # 将每两个 token 做平均池化\n",
    "        #     slow_x = slow_x.reshape(slow_T, -1, 2, D).mean(dim=2)\n",
    "\n",
    "        # slow_tokens = slow_x.reshape(1, -1, D)  # flatten 所有帧 token -> shape=(1, T_s*N_slow, D)\n",
    "\n",
    "        slow_x = rearrange(slow_x, 't (h w) d -> t d h w', h=H, w=H)\n",
    "\n",
    "        if self.cfg.slow_spatial_pool == \"2x2_max\":\n",
    "            pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            slow_x = pool(slow_x)  # (T_s, D, H/2, H/2)\n",
    "        elif self.cfg.slow_spatial_pool == \"2x2_avg\":\n",
    "            pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            slow_x = pool(slow_x)\n",
    "\n",
    "        _, _, H_slow, W_slow = slow_x.shape\n",
    "        slow_tokens = rearrange(slow_x, 't d h w -> t (h w) d')\n",
    "        slow_tokens = slow_tokens.reshape(1, slow_T*H_slow*W_slow, D)\n",
    "\n",
    "        # Fast\n",
    "        fast_x = x  # (T, N, D)\n",
    "        # reshape -> D, T, H, H\n",
    "        fast_x = rearrange(fast_x, 't (h w) d -> d t h w', h=H, w=H)\n",
    "        pool2 = nn.AdaptiveAvgPool2d(self.cfg.fast_output_size) # 自适应平均池化到 fast_output_size=(4,4)\n",
    "        fast_x = pool2(fast_x)  # (D, T, 4, 4)\n",
    "\n",
    "        D, T, Hf, Wf = fast_x.shape\n",
    "        fast_x = rearrange(fast_x, 'd t h w -> t h w d') # 对应之前的 rearrange， (T, 4, 4, D)\n",
    "        fast_tokens = fast_x.reshape(1, T*Hf*Wf, D) # flatten (1, T*4*4, D)\n",
    "\n",
    "        out = torch.cat([slow_tokens, fast_tokens], dim=1)\n",
    "\n",
    "        if debug:\n",
    "            info[\"input_shape\"] = (T, N, D)\n",
    "            info[\"slow_idx\"] = slow_idx.tolist()\n",
    "            info[\"slow_tokens_shape\"] = slow_tokens.shape\n",
    "            info[\"fast_tokens_shape\"] = fast_tokens.shape\n",
    "            info[\"output_shape\"] = out.shape\n",
    "            return out, info\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3070d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens:        (64, 196, 512)   (T, N, D)\n",
      "Slow frame indices:  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 63]\n",
      "Slow tokens shape:   torch.Size([1, 6272, 512])\n",
      "Fast tokens shape:   torch.Size([1, 1024, 512])\n",
      "---------------------------------------\n",
      "Fused output shape:  torch.Size([1, 7296, 512])\n",
      "ratio:   0.58\n"
     ]
    }
   ],
   "source": [
    "def slowfast_debug_demo():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    T, H, D =64, 14, 512  # ViT: 14x14 patches\n",
    "    N = H*H\n",
    "    x = torch.randn(T, N, D)\n",
    "\n",
    "    cfg = SlowFastConfig(\n",
    "        slow_num_frames=32,\n",
    "        slow_spatial_pool=\"1d_max\",\n",
    "        fast_output_size=(4,4)\n",
    "    )\n",
    "\n",
    "    model = TokenSlowFastAggregator(cfg, num_patches_per_side=H)\n",
    "    y, info = model.forward(x, debug=True)\n",
    "\n",
    "    total_input_tokens = T * N\n",
    "    total_output_tokens = info['output_shape'][1]\n",
    "    ratio = total_output_tokens / total_input_tokens\n",
    "\n",
    "    print(f\"Input tokens:        {info['input_shape']}   (T, N, D)\")\n",
    "    print(f\"Slow frame indices:  {info['slow_idx']}\")\n",
    "    print(f\"Slow tokens shape:   {info['slow_tokens_shape']}\")\n",
    "    print(f\"Fast tokens shape:   {info['fast_tokens_shape']}\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(f\"Fused output shape:  {info['output_shape']}\")\n",
    "    print(f\"ratio:   {ratio:.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    slowfast_debug_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
